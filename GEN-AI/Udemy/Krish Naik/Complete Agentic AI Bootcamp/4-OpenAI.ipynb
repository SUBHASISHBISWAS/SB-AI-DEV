{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-16T17:48:13.722029Z",
     "start_time": "2025-09-16T17:48:13.710894Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:48:14.198672Z",
     "start_time": "2025-09-16T17:48:14.180987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ],
   "id": "5b6886253af1e796",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x10cbaadc0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10cbb0340> root_client=<openai.OpenAI object at 0x10a2294f0> root_async_client=<openai.AsyncOpenAI object at 0x10cbaae20> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:49:33.961837Z",
     "start_time": "2025-09-16T17:49:05.414165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result=llm.invoke(\"What is generative AI?\")\n",
    "result"
   ],
   "id": "90f036491bb322d1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Generative AI refers to a category of artificial intelligence algorithms designed to produce new content, such as text, images, music, or other forms of media. Unlike traditional AI models that typically perform classification or regression tasks based on existing data, generative AI models learn patterns and structures within the input data and then use that understanding to generate novel outputs that mimic the original data.\\n\\nThere are several techniques and frameworks within generative AI, with some of the most prominent being:\\n\\n1. **Generative Adversarial Networks (GANs):** These consist of two neural networks, a generator and a discriminator, that are trained simultaneously. The generator creates new data instances, while the discriminator evaluates them. The goal is for the generator to produce data that is indistinguishable from real data, effectively \"fooling\" the discriminator.\\n\\n2. **Variational Autoencoders (VAEs):** These models encode input data into a compressed latent space and then decode it back into the original data domain. VAEs are probabilistic models that also aim to generate new data by sampling from the latent space.\\n\\n3. **Transformer Models:** These include architectures such as GPT (Generative Pre-trained Transformer), which are particularly effective at generating text. Transformers use self-attention mechanisms to understand the context and relationships within the data, allowing for the creation of coherent and contextually relevant text.\\n\\nGenerative AI has a wide range of applications, including but not limited to:\\n\\n- **Text Generation:** Automated writing, chatbots, and language translation.\\n- **Image and Video Creation:** Generating photorealistic images or videos, deepfakes, art creation.\\n- **Music Composition:** Producing new music tracks or assisting composers.\\n- **Design and Creativity:** Helping in design processes by generating prototypes or variations.\\n\\nWhile generative AI holds significant promise and potential, it also raises ethical concerns, such as the potential for misuse in creating misleading information or intellectual property issues. As such, the development and deployment of generative AI technologies require careful consideration of ethical guidelines and societal impacts.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 411, 'prompt_tokens': 13, 'total_tokens': 424, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f33640a400', 'id': 'chatcmpl-CGU5sb3s6ZAvUpCUv9SeqcmZOjbVH', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--8b01224f-34e7-4ca7-8f16-83ad46c66c2d-0', usage_metadata={'input_tokens': 13, 'output_tokens': 411, 'total_tokens': 424, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:51:49.330855Z",
     "start_time": "2025-09-16T17:51:49.242352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ],
   "id": "6948e80c790aa80f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:55:16.620169Z",
     "start_time": "2025-09-16T17:55:11.999669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chain=prompt|llm\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ],
   "id": "5f984c3181e3a2c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langsmith is a suite of tools and services designed to enhance the development, testing, and deployment of applications that use large language models (LLMs) and chat models. Building on the core capabilities of the Langchain framework, Langsmith focuses on improving the reliability, observability, and performance of applications by enabling developers to evaluate and monitor their LLM-powered applications more effectively.\\n\\nKey features of Langsmith include:\\n\\n1. **Testing and Evaluation:** Langsmith provides mechanisms to create evaluations for language model applications. This allows developers to systematically test the behavior and performance of their models, identifying areas where the models excel or struggle.\\n\\n2. **Observability and Logging:** The platform enhances observability by offering detailed logging and tracing of interactions between applications and language models. This feature helps developers understand model behavior and performance in real-world scenarios.\\n\\n3. **Debugging and Monitoring:** Langsmith allows for real-time monitoring of deployed applications, facilitating debugging and troubleshooting. Developers can detect and diagnose issues as they arise, ensuring smoother operation and improved user experiences.\\n\\n4. **Performance Optimization:** By providing insights into how language models handle different tasks, Langsmith helps developers optimize their applications for better efficiency and effectiveness.\\n\\nOverall, Langsmith supports the development lifecycle of LLM applications, from initial prototyping through to production deployment, helping ensure that applications are robust, reliable, and efficient.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 271, 'prompt_tokens': 33, 'total_tokens': 304, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_1827dd0c55', 'id': 'chatcmpl-CGUBUjGl8x8AuHRR0P8wiU0ZDLGPr', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--d0492fb1-4425-4c49-8490-71a9ce9d690b-0' usage_metadata={'input_tokens': 33, 'output_tokens': 271, 'total_tokens': 304, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:55:17.825615Z",
     "start_time": "2025-09-16T17:55:17.817711Z"
    }
   },
   "cell_type": "code",
   "source": "type(response)",
   "id": "b74d96da36f03d98",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-16T17:56:23.319092Z",
     "start_time": "2025-09-16T17:56:19.282984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ],
   "id": "ecc310e4746182de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a software tool developed to enhance the capabilities of LangChain applications. It focuses on enabling developers to build more reliable, observable, and testable applications that leverage large language models. Langsmith provides features such as detailed tracing, execution monitoring, and debugging support for applications using LangChain. It is particularly useful for identifying issues with language model tasks, optimizing performance, and ensuring robustness in applications that deploy complex language-driven processes. These capabilities make Langsmith a valuable tool for developers working on integrating language models into AI solutions, helping them manage the intricate interactions and dependencies that such models often entail.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2b6c48279a28d8e1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
