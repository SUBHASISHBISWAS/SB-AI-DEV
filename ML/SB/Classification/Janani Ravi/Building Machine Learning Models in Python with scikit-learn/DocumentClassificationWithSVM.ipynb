{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d4dce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " The data set that we'll use for this problem is available with the scikit-learn library. \n",
    " Scikit-learn contains a number of data sets that can be used to train and validate models. \n",
    " We'll use the fetch 20 newsgroups module to retrieve the data set. \n",
    " This contains roughly 20, 000 newsgroup documents which are split across 20 newsgroups.\n",
    " \n",
    " Each one of these 20 newsgroups corresponds to a particular topic. \n",
    " The return value from this function is a dictionary and these are the keys within the dictionary. \n",
    "'''\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "tewnty_train=fetch_20newsgroups(subset='train',shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb1f77a",
   "metadata": {},
   "source": [
    "http://qwone.com/~jason/20Newsgroups/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08c5f9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The return value from this function is a dictionary and these are the keys within the dictionary. \n",
    "\n",
    "The data key is what contains our training data. These are our newsgroup documents. \n",
    "\n",
    "Target names are the newsgroups to which these documents belong.\n",
    "These are the labels or the y values associated with each document.\n",
    "'''\n",
    "tewnty_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dd2de73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Here is a document sample from the training data set. \n",
    "This is an email related to cars. \n",
    "\n",
    "'''\n",
    "print(tewnty_train.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65f43e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Here are the 20 newsgroups to which these documents belong. \n",
    "They range from sports to computers to politics. \n",
    "\n",
    "'''\n",
    "'''\n",
    "tewnty_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18d2cce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 4, 4, ..., 3, 1, 8])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Our categorical variables need to be expressed in numeric form and that's what the target key holds.\n",
    "'''\n",
    "tewnty_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7806d4d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Every document is x data and and we will represent it in numeric form using the count vectorizer. \n",
    "\n",
    "We'll call the count vectorizers fit transform method on our training data. \n",
    "\n",
    "The output of the count vectorizer is a sparse matrix. \n",
    "\n",
    "Every word is identified uniquely using its document ID and its unique word ID \n",
    "and the frequency of the word in that document is specified.\n",
    "\n",
    "Here is the shape of our sparse matrix. \n",
    "\n",
    "'''\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect=CountVectorizer()\n",
    "X_train_counts=count_vect.fit_transform(tewnty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23e489f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 56979)\t3\n",
      "  (0, 75358)\t2\n",
      "  (0, 123162)\t2\n",
      "  (0, 118280)\t2\n",
      "  (0, 50527)\t2\n",
      "  (0, 124031)\t2\n",
      "  (0, 85354)\t1\n",
      "  (0, 114688)\t1\n",
      "  (0, 111322)\t1\n",
      "  (0, 123984)\t1\n",
      "  (0, 37780)\t5\n",
      "  (0, 68532)\t3\n",
      "  (0, 114731)\t5\n",
      "  (0, 87620)\t1\n",
      "  (0, 95162)\t1\n",
      "  (0, 64095)\t1\n",
      "  (0, 98949)\t1\n",
      "  (0, 90379)\t1\n",
      "  (0, 118983)\t1\n",
      "  (0, 89362)\t3\n",
      "  (0, 79666)\t1\n",
      "  (0, 40998)\t1\n",
      "  (0, 92081)\t1\n",
      "  (0, 76032)\t1\n",
      "  (0, 4605)\t1\n",
      "  :\t:\n",
      "  (0, 37565)\t1\n",
      "  (0, 113986)\t1\n",
      "  (0, 83256)\t1\n",
      "  (0, 86001)\t1\n",
      "  (0, 51730)\t1\n",
      "  (0, 109271)\t1\n",
      "  (0, 128026)\t1\n",
      "  (0, 96144)\t1\n",
      "  (0, 78784)\t1\n",
      "  (0, 63363)\t1\n",
      "  (0, 90252)\t1\n",
      "  (0, 123989)\t1\n",
      "  (0, 67156)\t1\n",
      "  (0, 128402)\t2\n",
      "  (0, 62221)\t1\n",
      "  (0, 57308)\t1\n",
      "  (0, 76722)\t1\n",
      "  (0, 94362)\t1\n",
      "  (0, 78955)\t1\n",
      "  (0, 114428)\t1\n",
      "  (0, 66098)\t1\n",
      "  (0, 35187)\t1\n",
      "  (0, 35983)\t1\n",
      "  (0, 128420)\t1\n",
      "  (0, 86580)\t1\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "You can explore the output of the count vectorizer on the very first document. \n",
    "Here you can see the document ID, the word ID and the associated frequency.\n",
    "'''\n",
    "print(X_train_counts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96749be8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
