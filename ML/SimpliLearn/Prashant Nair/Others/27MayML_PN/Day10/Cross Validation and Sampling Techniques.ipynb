{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 6 columns):\n",
      "Id               150 non-null int64\n",
      "SepalLengthCm    150 non-null float64\n",
      "SepalWidthCm     150 non-null float64\n",
      "PetalLengthCm    150 non-null float64\n",
      "PetalWidthCm     150 non-null float64\n",
      "Species          150 non-null object\n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 7.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.iloc[:,1:5].values\n",
    "label = data.iloc[:,5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "algo = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 0.93333333, 0.93333333,\n",
       "       0.93333333, 0.8       , 0.93333333, 1.        , 1.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross Validation for Accuracy Score\n",
    "# Getting an idea of what can be the best possible score I can achieve\n",
    "# for the given dataset w.r.t the algo\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(algo,\n",
    "               features,\n",
    "               label,\n",
    "               cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "?cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score is 0.9555555555555556 and Testing score is 1.0 for Sample Split 1\n",
      "Training Score is 0.9629629629629629 and Testing score is 0.8 for Sample Split 2\n",
      "Training Score is 0.9481481481481482 and Testing score is 1.0 for Sample Split 3\n",
      "Training Score is 0.9481481481481482 and Testing score is 0.9333333333333333 for Sample Split 4\n",
      "Training Score is 0.9629629629629629 and Testing score is 1.0 for Sample Split 5\n",
      "Training Score is 0.9703703703703703 and Testing score is 0.9333333333333333 for Sample Split 6\n",
      "Training Score is 0.9629629629629629 and Testing score is 1.0 for Sample Split 7\n",
      "Training Score is 0.9703703703703703 and Testing score is 0.9333333333333333 for Sample Split 8\n",
      "Training Score is 0.9555555555555556 and Testing score is 1.0 for Sample Split 9\n",
      "Training Score is 0.9703703703703703 and Testing score is 0.8666666666666667 for Sample Split 10\n"
     ]
    }
   ],
   "source": [
    "# Fold Validation Technique\n",
    "# K-Fold Cross validation Technique\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=10,\n",
    "             shuffle=True,\n",
    "             random_state=1)\n",
    "i = 0\n",
    "for train,test in kfold.split(features):\n",
    "    i = i + 1\n",
    "    X_train,X_test = features[train],features[test]\n",
    "    y_train,y_test= label[train],label[test]\n",
    "    model.fit(X_train,y_train)\n",
    "    print('Training Score is {} and Testing score is {} for Sample Split {}'\n",
    "          .format(model.score(X_train,y_train),model.score(X_test,y_test),i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=10,\n",
    "             shuffle=True,\n",
    "             random_state=1)\n",
    "i = 0\n",
    "for train,test in kfold.split(features):\n",
    "    i = i+1\n",
    "    if i == 1:\n",
    "        X_train_final,X_test_final,y_train_final,y_test_final = features[train],features[test],label[train],label[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "finalModel = LogisticRegression()\n",
    "finalModel.fit(X_train_final,y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalModel.score(X_train_final,y_train_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalModel.score(X_test_final,y_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "?KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score is 0.9523809523809523 and Testing score is 0.9777777777777777 for Sample Split 1\n",
      "Training Score is 0.9714285714285714 and Testing score is 0.9333333333333333 for Sample Split 2\n",
      "Training Score is 0.9619047619047619 and Testing score is 0.9333333333333333 for Sample Split 3\n",
      "Training Score is 0.9523809523809523 and Testing score is 0.9555555555555556 for Sample Split 4\n",
      "Training Score is 0.9523809523809523 and Testing score is 0.9777777777777777 for Sample Split 5\n",
      "Training Score is 0.9523809523809523 and Testing score is 0.9777777777777777 for Sample Split 6\n",
      "Training Score is 0.9619047619047619 and Testing score is 0.9777777777777777 for Sample Split 7\n",
      "Training Score is 0.9523809523809523 and Testing score is 0.9777777777777777 for Sample Split 8\n",
      "Training Score is 0.9619047619047619 and Testing score is 0.9333333333333333 for Sample Split 9\n",
      "Training Score is 0.9714285714285714 and Testing score is 0.8888888888888888 for Sample Split 10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=10,\n",
    "                            test_size=0.3,\n",
    "                            random_state= 1)\n",
    "i = 0\n",
    "for train,test in sss.split(features,label):\n",
    "    i = i + 1\n",
    "    X_train,X_test = features[train],features[test]\n",
    "    y_train,y_test= label[train],label[test]\n",
    "    model.fit(X_train,y_train)\n",
    "    print('Training Score is {} and Testing score is {} for Sample Split {}'\n",
    "          .format(model.score(X_train,y_train),model.score(X_test,y_test),i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True  True]\n",
      "Index(['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm'], dtype='object')\n",
      "[2 3 1 1]\n"
     ]
    }
   ],
   "source": [
    "# RFE can be applied for the below following:\n",
    "# Based on Co-effient values --- Regression (LinearRegression, SVR, DecisionTreeRegressor, RForestR)\n",
    "# Based on feature_importance --- Classification (DecisionTreeClassifier & RandomForestClassifier)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "algo = DecisionTreeClassifier()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "algo2 = RandomForestClassifier()\n",
    "from sklearn.feature_selection import RFE\n",
    "selectFeatures = RFE(estimator=algo2,\n",
    "                    step= 1) #It will remove one feature at each iteration\n",
    "selectFeatures.fit(features,label)\n",
    "print(selectFeatures.support_)\n",
    "print(data.columns[1:5])\n",
    "print(selectFeatures.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9916666666666667\n",
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "# RFE ---> StratifiedShuffleSplit ---> model with good split\n",
    "\n",
    "finalFeatures = features[:,2:4]\n",
    "#print(finalFeatures)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(finalFeatures,\n",
    "                                                label,\n",
    "                                                test_size=0.2,\n",
    "                                                random_state=10)\n",
    "algo.fit(X_train,y_train)\n",
    "print(algo.score(X_train,y_train))\n",
    "print(algo.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of Feature Importance\n",
    "#Applicable only for DecisionTreeClassifier and RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(features,\n",
    "                                                label,\n",
    "                                                test_size=0.2,\n",
    "                                                random_state=10)\n",
    "algo = DecisionTreeClassifier()\n",
    "algo.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01669798, 0.02540478, 0.90945348, 0.04844377])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.feature_importances_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
