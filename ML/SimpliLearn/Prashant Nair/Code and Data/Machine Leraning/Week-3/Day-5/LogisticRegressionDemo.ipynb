{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A famous shopping mall company has hired you as a ML engineer . Your task is to create a  model that can predict whether the customer will purchase the product from the website or not based on customer's age and estimated salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shoppingData = pd.read_csv('Social_Network_Ads.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 5 columns):\n",
      "User ID            400 non-null int64\n",
      "Gender             400 non-null object\n",
      "Age                400 non-null int64\n",
      "EstimatedSalary    400 non-null int64\n",
      "Purchased          400 non-null int64\n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 15.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#Check for missing data\n",
    "shoppingData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    257\n",
       "1    143\n",
       "Name: Purchased, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check whether the dataset is balanced or not\n",
    "shoppingData.Purchased.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. This use-case is a Binary Classification Use-case\n",
    "#2. This dataset is an UNBALANCED dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperate my data is features and label\n",
    "#Rule of Classification specific to SKLEARN\n",
    "#Features ---> 2d\n",
    "#Label ------> 1d\n",
    "\n",
    "features = shoppingData.iloc[:,[2,3]].values\n",
    "label = shoppingData.iloc[:,4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 0.6875  Training 0.63125  Random State 3\n",
      "Testing 0.8875  Training 0.834375  Random State 4\n",
      "Testing 0.6625  Training 0.6375  Random State 5\n",
      "Testing 0.675  Training 0.634375  Random State 7\n",
      "Testing 0.675  Training 0.634375  Random State 8\n",
      "Testing 0.65  Training 0.640625  Random State 10\n",
      "Testing 0.6625  Training 0.6375  Random State 11\n",
      "Testing 0.675  Training 0.634375  Random State 16\n",
      "Testing 0.7  Training 0.628125  Random State 17\n",
      "Testing 0.7  Training 0.628125  Random State 21\n",
      "Testing 0.65  Training 0.640625  Random State 24\n",
      "Testing 0.6625  Training 0.6375  Random State 25\n",
      "Testing 0.875  Training 0.834375  Random State 26\n",
      "Testing 0.675  Training 0.634375  Random State 27\n",
      "Testing 0.7  Training 0.628125  Random State 28\n",
      "Testing 0.6875  Training 0.63125  Random State 29\n",
      "Testing 0.6875  Training 0.63125  Random State 31\n",
      "Testing 0.6625  Training 0.6375  Random State 37\n",
      "Testing 0.675  Training 0.640625  Random State 39\n",
      "Testing 0.7  Training 0.628125  Random State 40\n",
      "Testing 0.6625  Training 0.64375  Random State 42\n",
      "Testing 0.85  Training 0.790625  Random State 46\n",
      "Testing 0.65  Training 0.640625  Random State 48\n",
      "Testing 0.675  Training 0.634375  Random State 50\n",
      "Testing 0.65  Training 0.640625  Random State 51\n",
      "Testing 0.65  Training 0.640625  Random State 54\n",
      "Testing 0.65  Training 0.64375  Random State 56\n",
      "Testing 0.6625  Training 0.6375  Random State 58\n",
      "Testing 0.6875  Training 0.6375  Random State 59\n",
      "Testing 0.7  Training 0.628125  Random State 60\n",
      "Testing 0.6625  Training 0.6375  Random State 62\n",
      "Testing 0.6875  Training 0.63125  Random State 63\n",
      "Testing 0.65  Training 0.640625  Random State 66\n",
      "Testing 0.65  Training 0.640625  Random State 74\n",
      "Testing 0.65  Training 0.640625  Random State 75\n",
      "Testing 0.6875  Training 0.63125  Random State 76\n",
      "Testing 0.6875  Training 0.63125  Random State 80\n",
      "Testing 0.675  Training 0.634375  Random State 81\n",
      "Testing 0.7  Training 0.628125  Random State 83\n",
      "Testing 0.675  Training 0.634375  Random State 84\n",
      "Testing 0.675  Training 0.634375  Random State 86\n",
      "Testing 0.65  Training 0.640625  Random State 87\n",
      "Testing 0.675  Training 0.634375  Random State 90\n",
      "Testing 0.675  Training 0.640625  Random State 91\n",
      "Testing 0.7  Training 0.628125  Random State 93\n",
      "Testing 0.85  Training 0.834375  Random State 94\n",
      "Testing 0.65  Training 0.640625  Random State 97\n",
      "Testing 0.7875  Training 0.784375  Random State 99\n",
      "Testing 0.675  Training 0.634375  Random State 101\n",
      "Testing 0.6625  Training 0.6375  Random State 102\n",
      "Testing 0.725  Training 0.621875  Random State 103\n",
      "Testing 0.65  Training 0.640625  Random State 106\n",
      "Testing 0.65  Training 0.640625  Random State 109\n",
      "Testing 0.675  Training 0.634375  Random State 116\n",
      "Testing 0.65  Training 0.640625  Random State 117\n",
      "Testing 0.675  Training 0.634375  Random State 119\n",
      "Testing 0.65  Training 0.640625  Random State 120\n",
      "Testing 0.6625  Training 0.6375  Random State 121\n",
      "Testing 0.725  Training 0.653125  Random State 125\n",
      "Testing 0.65  Training 0.640625  Random State 127\n",
      "Testing 0.65  Training 0.640625  Random State 128\n",
      "Testing 0.6875  Training 0.63125  Random State 129\n",
      "Testing 0.6875  Training 0.63125  Random State 130\n",
      "Testing 0.6625  Training 0.6375  Random State 132\n",
      "Testing 0.6875  Training 0.63125  Random State 133\n",
      "Testing 0.675  Training 0.634375  Random State 134\n",
      "Testing 0.675  Training 0.640625  Random State 138\n",
      "Testing 0.7  Training 0.628125  Random State 139\n",
      "Testing 0.8375  Training 0.80625  Random State 141\n",
      "Testing 0.725  Training 0.621875  Random State 142\n",
      "Testing 0.6625  Training 0.6375  Random State 143\n",
      "Testing 0.6625  Training 0.6375  Random State 145\n",
      "Testing 0.875  Training 0.8125  Random State 150\n",
      "Testing 0.65  Training 0.640625  Random State 152\n",
      "Testing 0.6625  Training 0.6375  Random State 154\n",
      "Testing 0.675  Training 0.634375  Random State 155\n",
      "Testing 0.6625  Training 0.6375  Random State 159\n",
      "Testing 0.7125  Training 0.625  Random State 161\n",
      "Testing 0.675  Training 0.634375  Random State 162\n",
      "Testing 0.6625  Training 0.6375  Random State 163\n",
      "Testing 0.65  Training 0.640625  Random State 165\n",
      "Testing 0.6625  Training 0.6375  Random State 169\n",
      "Testing 0.675  Training 0.634375  Random State 170\n",
      "Testing 0.7125  Training 0.625  Random State 173\n",
      "Testing 0.65  Training 0.640625  Random State 176\n",
      "Testing 0.6625  Training 0.6375  Random State 178\n",
      "Testing 0.6625  Training 0.6375  Random State 179\n",
      "Testing 0.6625  Training 0.6375  Random State 180\n",
      "Testing 0.6625  Training 0.6375  Random State 181\n",
      "Testing 0.65  Training 0.640625  Random State 184\n",
      "Testing 0.6625  Training 0.6375  Random State 185\n",
      "Testing 0.675  Training 0.634375  Random State 188\n",
      "Testing 0.7375  Training 0.61875  Random State 189\n",
      "Testing 0.7  Training 0.628125  Random State 192\n",
      "Testing 0.65  Training 0.640625  Random State 193\n",
      "Testing 0.6875  Training 0.63125  Random State 194\n",
      "Testing 0.65  Training 0.640625  Random State 195\n",
      "Testing 0.6625  Training 0.6375  Random State 196\n",
      "Testing 0.675  Training 0.634375  Random State 198\n",
      "Testing 0.7625  Training 0.734375  Random State 204\n",
      "Testing 0.6625  Training 0.6375  Random State 209\n",
      "Testing 0.7  Training 0.628125  Random State 211\n",
      "Testing 0.65  Training 0.640625  Random State 212\n",
      "Testing 0.6625  Training 0.6375  Random State 215\n",
      "Testing 0.6625  Training 0.6375  Random State 217\n",
      "Testing 0.6875  Training 0.63125  Random State 220\n",
      "Testing 0.6625  Training 0.6375  Random State 223\n",
      "Testing 0.6625  Training 0.6375  Random State 225\n",
      "Testing 0.6625  Training 0.6375  Random State 226\n",
      "Testing 0.6875  Training 0.63125  Random State 229\n",
      "Testing 0.65  Training 0.640625  Random State 232\n",
      "Testing 0.7125  Training 0.625  Random State 233\n",
      "Testing 0.6625  Training 0.6375  Random State 234\n",
      "Testing 0.6625  Training 0.6375  Random State 235\n",
      "Testing 0.6875  Training 0.63125  Random State 238\n",
      "Testing 0.65  Training 0.640625  Random State 241\n",
      "Testing 0.725  Training 0.621875  Random State 242\n",
      "Testing 0.6625  Training 0.6375  Random State 244\n",
      "Testing 0.675  Training 0.634375  Random State 245\n",
      "Testing 0.6875  Training 0.63125  Random State 246\n",
      "Testing 0.7  Training 0.628125  Random State 247\n",
      "Testing 0.6875  Training 0.63125  Random State 248\n",
      "Testing 0.65  Training 0.640625  Random State 251\n",
      "Testing 0.7  Training 0.628125  Random State 252\n",
      "Testing 0.65  Training 0.640625  Random State 253\n",
      "Testing 0.675  Training 0.640625  Random State 255\n",
      "Testing 0.75  Training 0.615625  Random State 257\n",
      "Testing 0.7  Training 0.628125  Random State 260\n",
      "Testing 0.65  Training 0.640625  Random State 263\n",
      "Testing 0.6625  Training 0.6375  Random State 265\n",
      "Testing 0.6875  Training 0.63125  Random State 269\n",
      "Testing 0.6625  Training 0.6375  Random State 275\n",
      "Testing 0.7  Training 0.628125  Random State 276\n",
      "Testing 0.6625  Training 0.6375  Random State 277\n",
      "Testing 0.7  Training 0.628125  Random State 278\n",
      "Testing 0.7125  Training 0.625  Random State 279\n",
      "Testing 0.6875  Training 0.63125  Random State 282\n",
      "Testing 0.6875  Training 0.63125  Random State 283\n",
      "Testing 0.85  Training 0.846875  Random State 287\n",
      "Testing 0.6625  Training 0.6375  Random State 292\n",
      "Testing 0.65  Training 0.640625  Random State 293\n",
      "Testing 0.6625  Training 0.6375  Random State 294\n",
      "Testing 0.675  Training 0.634375  Random State 296\n",
      "Testing 0.675  Training 0.634375  Random State 300\n",
      "Testing 0.675  Training 0.634375  Random State 302\n",
      "Testing 0.6625  Training 0.6375  Random State 303\n",
      "Testing 0.725  Training 0.628125  Random State 305\n",
      "Testing 0.6875  Training 0.63125  Random State 306\n",
      "Testing 0.7  Training 0.634375  Random State 310\n",
      "Testing 0.7125  Training 0.625  Random State 311\n",
      "Testing 0.75  Training 0.734375  Random State 313\n",
      "Testing 0.7  Training 0.628125  Random State 315\n",
      "Testing 0.6625  Training 0.6375  Random State 317\n",
      "Testing 0.6625  Training 0.6375  Random State 319\n",
      "Testing 0.65  Training 0.640625  Random State 321\n",
      "Testing 0.7125  Training 0.625  Random State 322\n",
      "Testing 0.675  Training 0.634375  Random State 323\n",
      "Testing 0.6625  Training 0.6375  Random State 325\n",
      "Testing 0.7125  Training 0.625  Random State 327\n",
      "Testing 0.6625  Training 0.6375  Random State 328\n",
      "Testing 0.7  Training 0.628125  Random State 329\n",
      "Testing 0.65  Training 0.640625  Random State 330\n",
      "Testing 0.65  Training 0.640625  Random State 332\n",
      "Testing 0.65  Training 0.646875  Random State 335\n",
      "Testing 0.675  Training 0.634375  Random State 336\n",
      "Testing 0.7  Training 0.634375  Random State 340\n",
      "Testing 0.65  Training 0.640625  Random State 344\n",
      "Testing 0.6625  Training 0.6375  Random State 345\n",
      "Testing 0.7  Training 0.628125  Random State 346\n",
      "Testing 0.65  Training 0.640625  Random State 348\n",
      "Testing 0.8375  Training 0.828125  Random State 349\n",
      "Testing 0.6875  Training 0.63125  Random State 350\n",
      "Testing 0.675  Training 0.634375  Random State 352\n",
      "Testing 0.675  Training 0.634375  Random State 354\n",
      "Testing 0.6875  Training 0.63125  Random State 355\n",
      "Testing 0.6625  Training 0.6375  Random State 356\n",
      "Testing 0.7375  Training 0.61875  Random State 357\n",
      "Testing 0.6625  Training 0.6375  Random State 358\n",
      "Testing 0.6625  Training 0.64375  Random State 359\n",
      "Testing 0.7  Training 0.628125  Random State 360\n",
      "Testing 0.65  Training 0.640625  Random State 361\n",
      "Testing 0.6625  Training 0.6375  Random State 362\n",
      "Testing 0.65  Training 0.640625  Random State 363\n",
      "Testing 0.6625  Training 0.6375  Random State 364\n",
      "Testing 0.6875  Training 0.63125  Random State 365\n",
      "Testing 0.675  Training 0.640625  Random State 366\n",
      "Testing 0.6625  Training 0.6375  Random State 368\n",
      "Testing 0.65  Training 0.640625  Random State 370\n",
      "Testing 0.725  Training 0.621875  Random State 371\n",
      "Testing 0.65  Training 0.640625  Random State 373\n",
      "Testing 0.7  Training 0.628125  Random State 376\n",
      "Testing 0.675  Training 0.634375  Random State 379\n",
      "Testing 0.65  Training 0.646875  Random State 387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 0.6625  Training 0.6375  Random State 393\n",
      "Testing 0.7625  Training 0.759375  Random State 396\n",
      "Testing 0.7  Training 0.628125  Random State 397\n",
      "Testing 0.7125  Training 0.63125  Random State 400\n"
     ]
    }
   ],
   "source": [
    "#Get the best random_state for generalized model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "for i in range(1,401):\n",
    "    \n",
    "    X_train,X_test,y_train,y_test = train_test_split(features,\n",
    "                                                label,\n",
    "                                                test_size=0.2,\n",
    "                                                random_state=i)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    train_score = model.score(X_train,y_train)\n",
    "    test_score = model.score(X_test,y_test)\n",
    "    \n",
    "    if test_score > train_score:\n",
    "        print(\"Testing {}  Training {}  Random State {}\".format(test_score,train_score,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data as training set and testing set --- 80-20\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(features,\n",
    "                                                label,\n",
    "                                                test_size=0.2,\n",
    "                                                random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.834375\n",
      "0.8875\n"
     ]
    }
   ],
   "source": [
    "#Check Generalization of the model\n",
    "print(model.score(X_train,y_train))\n",
    "print(model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[238,  19],\n",
       "       [ 43, 100]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print Confusion Matrix\n",
    "#Create confusion  matrix of entire dataset to judge the quality of the model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(label, model.predict(features))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.93      0.88       257\n",
      "          1       0.84      0.70      0.76       143\n",
      "\n",
      "avg / total       0.84      0.84      0.84       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Since dataset is unbalanced\n",
    "from sklearn.metrics import classification_report\n",
    "cr = classification_report(label, model.predict(features))\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
