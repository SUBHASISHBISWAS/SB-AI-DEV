{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOz+9EA7GoBbsR13eqQZRIm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"2dxKnBFQDOXH"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"t2wToK-qqkNB","executionInfo":{"status":"ok","timestamp":1706646166342,"user_tz":360,"elapsed":29865,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}}},"outputs":[],"source":["%%capture\n","!pip install langchain==0.1.4 openai==1.10.0 langchain-openai"]},{"cell_type":"code","source":["import os\n","import getpass\n","\n","os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter Your OpenAI API Key:\")"],"metadata":{"id":"azqvOheLql3O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706646169962,"user_tz":360,"elapsed":3626,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"678c60b2-bfb0-41e6-cdf6-9eda2c40a641"},"execution_count":2,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter Your OpenAI API Key:··········\n"]}]},{"cell_type":"markdown","source":["# Serialization of Prompts in LangChain\n","\n","🌐 **Prompt Serialization in LangChain:**\n","\n","- 📁 **Save & Share Easily**: Turn prompts into files for simple storage and sharing.\n","\n","- 📄 **Choose Your Format**: Use JSON or YAML for easy-to-read files.\n","\n","- 🛠️ **Flexible Storage**: Keep all your data in one place or spread it out—it's up to you.\n","\n","- ⚡ **One-Stop Loading**: Regardless of the prompt type, loading them is a breeze.\n","\n","**Core Principles:**\n","\n","1. 👀**Readable by Humans**: JSON and YAML make prompts easy for us to read and edit.\n","\n","2. 📚 **Flexible Filing**: Whether you're a one-file wonder or a multiple-file maestro, LangChain's got you covered.\n","\n","With LangChain, managing and exchanging prompts is as smooth as sending an email!\n"],"metadata":{"id":"yZ1h776jqnQ4"}},{"cell_type":"markdown","source":["# Saving prompts"],"metadata":{"id":"wIOwDys6uEiQ"}},{"cell_type":"code","source":["from langchain import PromptTemplate\n","\n","template = \"\"\"You are an insightful question answering bot. A user will submit\\\n","questions, which are delimited by triple backticks, and you should respond in\\\n","an insighful manner.\n","\n","Question: ```{question}```\n","\n","Take a deep breath, and think step by step before answering.\n","\n","Answer:\n","\"\"\"\n","\n","prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n","prompt.save(\"/content/cot_prompt.json\")"],"metadata":{"id":"h77s5pAFuEsF","executionInfo":{"status":"ok","timestamp":1706646510351,"user_tz":360,"elapsed":660,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!cat /content/cot_prompt.json"],"metadata":{"id":"IEbumrAvuE0I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706646522109,"user_tz":360,"elapsed":223,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"5cfa2ddf-65b2-4d6b-f738-f1e1c072f0b4"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","    \"name\": null,\n","    \"input_variables\": [\n","        \"question\"\n","    ],\n","    \"input_types\": {},\n","    \"output_parser\": null,\n","    \"partial_variables\": {},\n","    \"template\": \"You are an insightful question answering bot. A user will submitquestions, which are delimited by triple backticks, and you should respond inan insighful manner.\\n\\nQuestion: ```{question}```\\n\\nTake a deep breath, and think step by step before answering.\\n\\nAnswer:\\n\",\n","    \"template_format\": \"f-string\",\n","    \"validate_template\": false,\n","    \"_type\": \"prompt\"\n","}"]}]},{"cell_type":"markdown","source":["# Loading prompts"],"metadata":{"id":"sbcmkaNPuE63"}},{"cell_type":"code","source":["# All prompts are loaded through the `load_prompt` function.\n","from langchain.prompts import load_prompt"],"metadata":{"id":"KwN_kiSNrnLq","executionInfo":{"status":"ok","timestamp":1706646538025,"user_tz":360,"elapsed":226,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/hwchase17/langchain-hub/master/prompts/memory/summarize/prompt.json"],"metadata":{"id":"y596ApG8sBiY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706646539290,"user_tz":360,"elapsed":491,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"7df2d134-97b6-46de-b8aa-5857ad7219b3"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-01-30 20:28:58--  https://raw.githubusercontent.com/hwchase17/langchain-hub/master/prompts/memory/summarize/prompt.json\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 904 [text/plain]\n","Saving to: ‘prompt.json’\n","\n","prompt.json         100%[===================>]     904  --.-KB/s    in 0s      \n","\n","2024-01-30 20:28:59 (42.1 MB/s) - ‘prompt.json’ saved [904/904]\n","\n"]}]},{"cell_type":"code","source":["!cat prompt.json"],"metadata":{"id":"qEpleayXsGc5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706646542013,"user_tz":360,"elapsed":208,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"8d858bcb-1465-45d0-ef19-c56c8cd8de03"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","    \"input_variables\": [\n","        \"summary\",\n","        \"new_lines\"\n","    ],\n","    \"output_parser\": null,\n","    \"template\": \"Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\\n\\nEXAMPLE\\nCurrent summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\\n\\nNew lines of conversation:\\nHuman: Why do you think artificial intelligence is a force for good?\\nAI: Because artificial intelligence will help humans reach their full potential.\\n\\nNew summary:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\\nEND OF EXAMPLE\\n\\nCurrent summary:\\n{summary}\\n\\nNew lines of conversation:\\n{new_lines}\\n\\nNew summary:\",\n","    \"template_format\": \"f-string\"\n","}"]}]},{"cell_type":"code","source":["prompt = load_prompt(\"prompt.json\")"],"metadata":{"id":"LF8cSBSesIZh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706646551815,"user_tz":360,"elapsed":133,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"426dfe09-b102-4458-d3a7-c221eb22ee35"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:langchain_core.prompts.loading:No `_type` key found, defaulting to `prompt`.\n"]}]},{"cell_type":"code","source":["print(prompt.template)"],"metadata":{"id":"Qz4fTR76sl8K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706646554941,"user_tz":360,"elapsed":164,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"60235c2a-04fb-4cfa-9746-502ac40e79af"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary.\n","\n","EXAMPLE\n","Current summary:\n","The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n","\n","New lines of conversation:\n","Human: Why do you think artificial intelligence is a force for good?\n","AI: Because artificial intelligence will help humans reach their full potential.\n","\n","New summary:\n","The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n","END OF EXAMPLE\n","\n","Current summary:\n","{summary}\n","\n","New lines of conversation:\n","{new_lines}\n","\n","New summary:\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"HtAHSsETD8X5"},"execution_count":null,"outputs":[]}]}