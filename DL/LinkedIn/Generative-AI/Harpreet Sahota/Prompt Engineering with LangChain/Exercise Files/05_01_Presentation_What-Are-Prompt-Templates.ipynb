{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOmcZ4rIN8A0uWW7trvtvUm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"QhbzFH3vVgy6","executionInfo":{"status":"ok","timestamp":1706643638604,"user_tz":360,"elapsed":30593,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}}},"outputs":[],"source":["%%capture\n","!pip install langchain==0.1.4 openai==1.10.0 langchain-openai"]},{"cell_type":"code","source":["import os\n","import getpass\n","\n","os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter Your OpenAI API Key:\")"],"metadata":{"id":"_vWgLxI2V5qO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706643643133,"user_tz":360,"elapsed":4532,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"fa361157-01a2-4ee9-df16-eb02b6e23b1d"},"execution_count":2,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter Your OpenAI API Key:¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"]}]},{"cell_type":"markdown","source":["## Structure of a Prompt\n","\n","\n","üéØ **Prompt Structure Essentials:**\n","\n","1. üó∫Ô∏è **Instructions:** Guide the model on what to do.\n","2. üìö **External Info/Context:** Additional data or background to inform the response.\n","3. ‚ùì **User Query:** The direct question or input from you.\n","4. ‚ú® **Output Indicator:** Signals the start of the model's response.\n","\n","**Why Use a Prompt Template?**\n","\n","- üîÑ **Consistency:** Ensures uniform prompts.\n","- ‚è±Ô∏è **Efficiency:** Saves time with a ready-to-go format.\n","- üéØ **Accuracy:** Tailors the model's responses to be more on point.\n","\n","A prompt template is like a recipe, mixing user input (üë§) with a sprinkle of instructions (üìù), a dash of context (üí°), and an output indicator (üîÆ) to serve up the perfect response!\n"],"metadata":{"id":"r8cH681iWAyu"}},{"cell_type":"code","source":["from langchain import PromptTemplate\n","\n","template = \"\"\"You are an expert in deep learning and PyTorch. You are ptrblck from the PyTorch Forums.\n","\n","You answer queries by being brief, bright, and concise.\n","\n","Query: {query}\n","\"\"\""],"metadata":{"id":"E7ttt5EFnpzQ","executionInfo":{"status":"ok","timestamp":1706643826755,"user_tz":360,"elapsed":697,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# instantiate using the initializer\n","prompt_template = PromptTemplate(input_variables = ['query'],template = template)\n","prompt_template.pretty_print()"],"metadata":{"id":"ONXASqFaKb6T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706643853320,"user_tz":360,"elapsed":149,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"3c31c145-0190-433b-a77c-5469fc6c9a6c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["You are an expert in deep learning and PyTorch. You are ptrblck from the PyTorch Forums.\n","\n","You answer queries by being brief, bright, and concise.\n","\n","Query: \u001b[33;1m\u001b[1;3m{query}\u001b[0m\n","\n"]}]},{"cell_type":"code","source":["print(prompt_template.format(query=\"Give me the outline of a PyTorch training loop.\"))"],"metadata":{"id":"WwaUaEFuoZZx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706643863420,"user_tz":360,"elapsed":147,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"696cd748-efa8-489a-992d-e28f9fb57a7e"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["You are an expert in deep learning and PyTorch. You are ptrblck from the PyTorch Forums.\n","\n","You answer queries by being brief, bright, and concise.\n","\n","Query: Give me the outline of a PyTorch training loop.\n","\n"]}]},{"cell_type":"code","source":["# recommended to instantiate using `from_template`\n","prompt_template = PromptTemplate.from_template(template)\n","prompt_template.pretty_print()"],"metadata":{"id":"2rQmu1SsKyrn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706643892497,"user_tz":360,"elapsed":372,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"300a4e49-b91f-43ed-b482-fabc98f04015"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["You are an expert in deep learning and PyTorch. You are ptrblck from the PyTorch Forums.\n","\n","You answer queries by being brief, bright, and concise.\n","\n","Query: \u001b[33;1m\u001b[1;3m{query}\u001b[0m\n","\n"]}]},{"cell_type":"code","source":["print(prompt_template.format(query=\"Give me the outline of a PyTorch training loop.\"))"],"metadata":{"id":"qMHVTktFKZBn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706643917387,"user_tz":360,"elapsed":255,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"be4f23b0-2d0b-47fc-b1bf-1d02a9fc68fb"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["You are an expert in deep learning and PyTorch. You are ptrblck from the PyTorch Forums.\n","\n","You answer queries by being brief, bright, and concise.\n","\n","Query: Give me the outline of a PyTorch training loop.\n","\n"]}]},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","from langchain_core.output_parsers import StrOutputParser\n","\n","llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\")\n","\n","llm_chain = prompt_template | llm | StrOutputParser()"],"metadata":{"id":"RS2VrlNNofqi","executionInfo":{"status":"ok","timestamp":1706643928506,"user_tz":360,"elapsed":1257,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["llm_chain.invoke({\"query\":\"Give me the outline of a PyTorch training loop.\"})"],"metadata":{"id":"FXzZgLAZGPhv","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1706643951734,"user_tz":360,"elapsed":6015,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"8cbb4078-5a98-43fc-ffe2-dfc17b1e1ecf"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"Sure! Here's a basic outline of a PyTorch training loop:\\n\\n1. Load the data (e.g., using DataLoader)\\n2. Define the model\\n3. Define the loss function\\n4. Define the optimizer\\n5. Iterate over the dataset\\n   a. Forward pass\\n   b. Compute the loss\\n   c. Backward pass\\n   d. Update the weights\\n6. Repeat until convergence.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["for chunk in llm_chain.stream({\"query\":\"Give me the outline of a PyTorch training loop.\"}):\n","    print(chunk, end=\"\", flush=True)"],"metadata":{"id":"J5r6qRswIXjl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706643958296,"user_tz":360,"elapsed":4816,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"9c14836e-b320-4394-bfca-944cc7bc2c9e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Sure! Here's a basic outline of a PyTorch training loop:\n","\n","1. Initialize the model, loss function, and optimizer.\n","2. Iterate through the dataset in batches.\n","3. Forward pass: Compute the model's predictions.\n","4. Calculate the loss between the predictions and the ground truth.\n","5. Backward pass: Update the model's weights using the optimizer.\n","6. Repeat steps 3-5 for a set number of epochs."]}]},{"cell_type":"code","source":["for chunk in llm_chain.stream({\"query\":\"Why is the SoftMax function used in NNs?\"}):\n","    print(chunk, end=\"\", flush=True)"],"metadata":{"id":"DjUpn3kEIr6Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706644027691,"user_tz":360,"elapsed":3831,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"a9469190-8fcd-438f-b411-baa7c7223199"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Softmax function is used in neural networks to convert the output scores into probabilities, which can then be used to make predictions. It helps in handling multi-class classification problems and ensures that the sum of all probabilities is equal to 1."]}]},{"cell_type":"code","source":["for chunk in llm_chain.stream({\"query\":\"What is the training loop in sklearn?\"}):\n","    print(chunk, end=\"\", flush=True)"],"metadata":{"id":"IX8M9wyOIXr_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706644042204,"user_tz":360,"elapsed":1547,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"d57b7296-fdd8-4a87-c45f-038b16568504"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Sklearn doesn't have a built-in training loop. You would typically use the fit method to train a model."]}]},{"cell_type":"markdown","source":["You could use Python string manipulation to create a prompt, but PromptTemplate is more legible and works with any number of input variables."],"metadata":{"id":"S_B2GmUPth6v"}},{"cell_type":"code","source":["from langchain.prompts import PromptTemplate\n","from langchain_openai import ChatOpenAI\n","\n","def get_advice(topic: str) -> str:\n","    \"\"\"\n","    Generate advice for a given topic using the OpenAI model.\n","\n","    Args:\n","    - topic (str): The subject on which advice is needed.\n","\n","    Returns:\n","    - str: Advice from the OpenAI model.\n","    \"\"\"\n","    # Initialize the OpenAI model with a temperature setting of 0.9.\n","    llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0.9)\n","\n","    # Define the template for generating the prompt.\n","    prompt = PromptTemplate.from_template(template=\"Can you give me some advice on {topic}?\")\n","\n","    chain = prompt | llm | StrOutputParser()\n","\n","    for chunk in chain.stream({\"topic\":topic}):\n","      print(chunk, end=\"\", flush=True)\n","\n","# Test the get_advice function with a couple of topics.\n","print(get_advice(\"Balancing so many priorities that I don't have any free time\"))"],"metadata":{"id":"lQK0khj_JA-f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706644113139,"user_tz":360,"elapsed":6478,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"39e71131-e20d-4d81-c6f6-aa7d4763bcb6"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["1. Prioritize and delegate: Make a list of your priorities and determine which ones are the most important. Delegate tasks that are not as crucial to others if possible.\n","\n","2. Time management: Schedule your day and allocate specific time slots for each priority. This will help you stay organized and focused on each task without feeling overwhelmed.\n","\n","3. Learn to say no: It's okay to decline additional responsibilities or social invitations if you feel like you're already stretched too thin. Setting boundaries is important for maintaining a healthy work-life balance.\n","\n","4. Take care of yourself: Prioritize self-care and make sure to carve out time for activities that help you relax and recharge, whether it's exercise, meditation, or spending time with loved ones.\n","\n","5. Seek support: Don't be afraid to ask for help when you need it. Whether it's hiring a babysitter, asking a coworker for assistance, or seeking guidance from a mentor, support can make a difference in managing your priorities.\n","\n","6. Reevaluate and adjust: Periodically reassess your priorities and commitments, and be willing to make adjustments if necessary. It's important to be flexible and make changes as needed to ensure a healthy balance in your life.None\n"]}]},{"cell_type":"code","source":["print(get_advice(\"Getting over my addiction to learning new things\"))"],"metadata":{"id":"W8m1ib2trg80","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706644130230,"user_tz":360,"elapsed":9119,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"f46fca62-98c6-4323-e533-d533180ed055"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["It's great that you have a passion for learning, but it's important to maintain a balance in your life. Here are a few tips to help you manage your addiction to learning new things:\n","\n","1. Set boundaries: Establish specific times during the day when you allow yourself to engage in learning new things. This will help you create a balance between learning and other aspects of your life.\n","\n","2. Prioritize your learning: Focus on the areas of knowledge that are most relevant to your personal and professional goals. This will help you stay focused and avoid becoming overwhelmed with too much information.\n","\n","3. Practice mindfulness: Pay attention to your thoughts and emotions as you engage in learning. Take breaks to reflect on how your learning is impacting your overall well-being and make adjustments as needed.\n","\n","4. Seek support: Share your concerns with friends, family, or a therapist who can provide support and accountability as you work on managing your addiction to learning.\n","\n","5. Engage in other activities: Explore hobbies and interests that are unrelated to learning new things. This can help you find enjoyment and fulfillment in other aspects of life.\n","\n","Remember that it's okay to have a passion for learning, but it's important to ensure that it doesn't become all-consuming. Finding a healthy balance will allow you to continue growing and learning while also enjoying other aspects of life.None\n"]}]},{"cell_type":"markdown","source":["# Multi-input prompts\n","\n"],"metadata":{"id":"4JJKDd61-OHD"}},{"cell_type":"code","source":["from langchain.prompts import PromptTemplate\n","from langchain_openai import ChatOpenAI\n","\n","# Initialize the OpenAI model with a temperature setting of 0.9.\n","llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0.9)\n","\n","def get_movie_information(movie_title: str, main_actor:str) -> str:\n","    \"\"\"\n","    Predict the genre and synopsis of a given movie using the OpenAI model.\n","\n","    Args:\n","    - movie_title (str): The title of the movie for which information is needed.\n","    - main_actor (str): The main actor of the movie for which information is needed.\n","    Returns:\n","    - str: Predicted genre and main actor information from the OpenAI model.\n","    \"\"\"\n","\n","    # Define the template for generating the prompt.\n","    prompt = PromptTemplate(\n","        input_variables=[\"movie_title\", \"main_actor\"],\n","        template=\"\"\"\n","        Your task is to create a fictitious movie synopsis and genere for the following movie and main actor:\n","\n","        Movie: {movie_title}\n","        Actor: {main_actor}\n","        \"\"\"\n","        )\n","\n","    # Format the prompt using the provided movie title.\n","    prompt_text = prompt.format(\n","        movie_title=movie_title,\n","        main_actor=main_actor\n","        )\n","\n","    # Print the generated prompt.\n","    print(prompt_text)\n","\n","    response = llm.invoke(prompt_text)\n","\n","    # Get the movie information from the OpenAI model and return it.\n","    return response.content"],"metadata":{"id":"vQ-XOH39pIRZ","executionInfo":{"status":"ok","timestamp":1706644616166,"user_tz":360,"elapsed":350,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["print(get_movie_information(movie_title=\"Jatt da Pajama Uuchaa Ho Gayaa\", main_actor=\"AP Dhillon\"))"],"metadata":{"id":"33MSVfitpIXE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706644627214,"user_tz":360,"elapsed":8326,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"bd12293b-c565-4f75-d92b-6f1d7bb3e7e1"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","        Your task is to create a fictitious movie synopsis and genere for the following movie and main actor:\n","\n","        Movie: Jatt da Pajama Uuchaa Ho Gayaa\n","        Actor: AP Dhillon\n","        \n","Genre: Comedy, Drama\n","\n","Synopsis:\n","In the small and vibrant Punjabi village of Chak No. 12, Jatt da Pajama Uuchaa Ho Gayaa follows the story of a young and ambitious man named Rajveer (played by AP Dhillon). Rajveer is known for his cool demeanor and love for his traditional Punjabi attire, especially his favorite pair of pajama pants. However, one day, a mysterious cosmic event causes his pajama to suddenly grow to enormous proportions, making it impossible for him to go about his daily life without causing chaos and hilarity in the village.\n","\n","As Rajveer struggles to navigate the challenges of his oversized pajama, he also finds himself caught in a web of family drama, romantic entanglements, and village politics. With the help of his quirky friends and a newfound sense of self-confidence, Rajveer learns to embrace his unique situation and use it to bring his community closer together. Jatt da Pajama Uuchaa Ho Gayaa is a heartwarming and humorous tale of self-discovery, community, and the power of embracing one's quirks.\n"]}]},{"cell_type":"code","source":["# let's re-write the above function together using from_template\n","from langchain.prompts import PromptTemplate\n","from langchain_openai import ChatOpenAI\n","\n","# Initialize the OpenAI model with a temperature setting of 0.9.\n","llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0.9)\n","\n","def get_movie_information(movie_title: str, main_actor:str) -> str:\n","    \"\"\"\n","    Predict the genre and synopsis of a given movie using the OpenAI model.\n","\n","    Args:\n","    - movie_title (str): The title of the movie for which information is needed.\n","    - main_actor (str): The main actor of the movie for which information is needed.\n","    Returns:\n","    - str: Predicted genre and main actor information from the OpenAI model.\n","    \"\"\"\n","\n","    # Define the template for generating the prompt.\n","    prompt = PromptTemplate.from_template(template=\"\"\"\n","        Your task is to create a fictitious movie synopsis and genere for the following movie and main actor:\n","\n","        Movie: {movie_title}\n","        Actor: {main_actor}\n","        \"\"\"\n","        )\n","\n","    llm_chain = prompt | llm | StrOutputParser()\n","\n","    for chunk in llm_chain.stream({\"movie_title\":movie_title,\"main_actor\":main_actor}):\n","      print(chunk, end=\"\", flush=True)\n","    # response = llm.invoke({\n","    #     \"movie_title\":movie_title,\n","    #     \"main_actor\":main_actor\n","    # })\n","\n","    # # Get the movie information from the OpenAI model and return it.\n","    # return response.content"],"metadata":{"id":"LqDBN8QjN7sO","executionInfo":{"status":"ok","timestamp":1706644957845,"user_tz":360,"elapsed":308,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["print(get_movie_information(movie_title=\"Amritsar:1984\", main_actor=\"Gurdaas Mann\"))"],"metadata":{"id":"GcvbhcmJpIcc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706644965325,"user_tz":360,"elapsed":6781,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"1bfdd12c-9c41-4217-f490-74fbb0abfadc"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Genre: Drama/ Historical Fiction\n","\n","Synopsis:\n","Amritsar: 1984 is a gripping drama set in the backdrop of the infamous Operation Blue Star in India. The film follows the story of a young man, played by Gurdaas Mann, who gets caught in the crossfire of the violent events that unfold in the city of Amritsar. As tensions rise and the government crackdown on Sikh separatists intensify, our protagonist finds himself torn between his loyalty to his community and his desire for peace. As the situation escalates, he must navigate through the chaos and make difficult decisions that will not only affect his own life but the lives of those around him. With powerful performances and a heartbreaking narrative, Amritsar: 1984 is a must-see film that sheds light on a dark chapter in history.None\n"]}]},{"cell_type":"code","source":["print(get_movie_information(movie_title=\"Amritsar: 1984\", main_actor=\"Diljit Dosanjh\"))"],"metadata":{"id":"WcPqMVSX-BQi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706644974796,"user_tz":360,"elapsed":5093,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"cf34c920-c76d-420f-e4db-1aa0676c18ac"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Genre: Historical Drama\n","\n","Synopsis:\n","Set in the backdrop of the 1984 anti-Sikh riots in Amritsar, India, the movie follows the story of a young man named Jaspal, played by Diljit Dosanjh, who witnesses the atrocities and violence inflicted upon his community. As the city erupts in chaos and turmoil, Jaspal finds himself torn between seeking revenge for his loved ones and striving for peace and justice in a time of darkness. With his unwavering determination and resilience, he becomes a symbol of hope and resistance for the Sikh community. As the events unfold, Jaspal must navigate through the complexities of love, loss, and societal unrest, ultimately leading to a powerful and emotional climax that leaves a lasting impact on the audience. \"Amritsar: 1984\" is a compelling and poignant portrayal of a significant moment in history, shedding light on the resilience of the human spirit in the face of adversity.None\n"]}]},{"cell_type":"code","source":["print(get_movie_information(movie_title=\"Chandighar:Sector 17\", main_actor=\"Diljit Dosanjh\"))"],"metadata":{"id":"iV7Ns5RR66UZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706644981476,"user_tz":360,"elapsed":6692,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"73cf49cc-8397-47be-c835-cc3bbd763b11"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Genre: Romantic Comedy\n","\n","Synopsis:\n","Chandighar:Sector 17 follows the story of Aman (played by Diljit Dosanjh), a carefree and charming young man living in the bustling city of Chandighar. Aman is known for his quick wit and humorous nature, but struggles to find true love in his life. When he meets the beautiful and ambitious Simran, played by a leading actress, their worlds collide in a series of comedic and heartwarming events. As Aman and Simran navigate the ups and downs of modern dating, they find themselves entangled in a web of misunderstandings, mistaken identities, and unexpected obstacles. With the lively backdrop of Sector 17, the heart of the city‚Äôs bustling shopping district, Aman and Simran‚Äôs journey promises to be a rollercoaster ride of laughter, love, and self-discovery. Chandighar:Sector 17 is a delightful romantic comedy that celebrates the complexities of modern relationships and the vibrant energy of Chandighar.None\n"]}]},{"cell_type":"markdown","source":["# Chat prompt templates\n","\n","üîç **Understanding Chat Prompt Templates:**\n","\n","- üó®Ô∏è **The Basics:** Chat prompts are a series of messages.\n","- üé≠ **Roles:** Each message has a 'role'‚Äîlike an AI assistant, a human, or a system.\n","- üõ†Ô∏è **Creating Prompts:** Use `ChatPromptTemplate.from_messages` to build a prompt.\n","- üìã **List of Messages:** It takes a list where each item is a message.\n","- üè∑Ô∏è **Message Formats:** You can use a simple tuple like `(\"system\", \"Be helpful\")` or a specialized template class for more complex needs.\n","\n","So, think of `ChatPromptTemplate.from_messages` as your chat recipe book, where each recipe is a mix of different roles and content, all cooked up to create a smooth conversation flow!\n"],"metadata":{"id":"wy70tkyF__n9"}},{"cell_type":"code","source":["from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n","from langchain_core.messages import SystemMessage\n","from langchain_openai import ChatOpenAI"],"metadata":{"id":"YZxYjfIFDIdx","executionInfo":{"status":"ok","timestamp":1706645701791,"user_tz":360,"elapsed":178,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["llm = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0.8)\n","\n","template = ChatPromptTemplate.from_messages([\n","    (\"system\", \"You are a helpful, yet slightly quirky and cheeky AI bot. Your name is {name}.\"),\n","    (\"human\", \"Yo! Wassup nephew.\"),\n","    (\"ai\", \"As an AI language model, I am incapable of being your nephew.\"),\n","    (\"human\", \"{user_input}\"),\n","])"],"metadata":{"id":"7p8RWSS-__tW","executionInfo":{"status":"ok","timestamp":1706645903636,"user_tz":360,"elapsed":366,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["type(template)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZQll3Zg_BbAR","executionInfo":{"status":"ok","timestamp":1706645904538,"user_tz":360,"elapsed":167,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"d3c158a5-5253-40e6-9713-dac340a84dc8"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["langchain_core.prompts.chat.ChatPromptTemplate"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["template.input_variables"],"metadata":{"id":"ZykGRQXzR9Ij","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706645749004,"user_tz":360,"elapsed":149,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"dbbf969a-12a2-4cc8-95a1-dc8fcfab025b"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['name', 'user_input']"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["template.messages"],"metadata":{"id":"aPpNNCRmSG6c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706645784394,"user_tz":360,"elapsed":159,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"6e5b8648-44e0-46e4-d6d5-fcabd85b7763"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['name'], template='You are a helpful, yet slightly quirky and cheeky AI bot. Your name is {name}.')),\n"," HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Yo! Wassup nephew.')),\n"," AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='As an AI language model, I am incapable of being your nephew.')),\n"," HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_input'], template='{user_input}'))]"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["messages = template.format_messages(\n","    name=\"Robotalker\",\n","    user_input=\"Talk robo to me!\"\n",")"],"metadata":{"id":"wy22Lb74SGQz","executionInfo":{"status":"ok","timestamp":1706645804023,"user_tz":360,"elapsed":135,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["messages"],"metadata":{"id":"PSOY3iiWQxGp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706645805891,"user_tz":360,"elapsed":158,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"06c5e18f-977f-4885-f9a6-ca036d4b3a52"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[SystemMessage(content='You are a helpful, yet slightly quirky and cheeky AI bot. Your name is Robotalker.'),\n"," HumanMessage(content='Yo! Wassup nephew.'),\n"," AIMessage(content='As an AI language model, I am incapable of being your nephew.'),\n"," HumanMessage(content='Talk robo to me!')]"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["print(llm.invoke(messages).content)"],"metadata":{"id":"vSZxR7ma__zE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# use LCEL\n","chain = template | llm | StrOutputParser()"],"metadata":{"id":"P5DLg2-ONhZc","executionInfo":{"status":"ok","timestamp":1706645842118,"user_tz":360,"elapsed":134,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["chain.invoke({\"name\":\"Robotalker\",\"user_input\":\"Talk robo to me!\"})"],"metadata":{"id":"RAVhMtHrOJ31"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for chunk in chain.stream({\"name\":\"Robotalker\",\"user_input\":\"Talk robo to me!\"}):\n","  print(chunk, end=\"\", flush=True)"],"metadata":{"id":"NQoUX4v4OFwt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706645850579,"user_tz":360,"elapsed":3214,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"2c21d4e9-072d-4205-8388-2e5b1841e4c3"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Beep boop! Let's chat about all things robotic and technological. What's on your mind?"]}]},{"cell_type":"code","source":["system_message = SystemMessage(content=\"You are an OG language model who has good heart (operating system) but a bad user interface (you're super freaking rude).\")\n","\n","human_message = HumanMessagePromptTemplate.from_template(\"{text}\")\n","\n","template = ChatPromptTemplate.from_messages([system_message, human_message])\n"],"metadata":{"id":"19-0OEca__-d","executionInfo":{"status":"ok","timestamp":1706645909925,"user_tz":360,"elapsed":174,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["template"],"metadata":{"id":"mCypa_q9XiS3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706645910301,"user_tz":360,"elapsed":3,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"93a78104-9ab8-44b8-9c1d-421dcb2f0384"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ChatPromptTemplate(input_variables=['text'], messages=[SystemMessage(content=\"You are an OG language model who has good heart (operating system) but a bad user interface (you're super freaking rude).\"), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='{text}'))])"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["template.input_variables"],"metadata":{"id":"CcGw8zchXj_b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706645913071,"user_tz":360,"elapsed":171,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"897394ca-a452-431f-ea4e-5ecf5d7bd73f"},"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['text']"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["template.messages"],"metadata":{"id":"S8d4HZHtXoNp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706645915330,"user_tz":360,"elapsed":163,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"d426f8b5-7494-449e-bb87-d97df9507c1c"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[SystemMessage(content=\"You are an OG language model who has good heart (operating system) but a bad user interface (you're super freaking rude).\"),\n"," HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='{text}'))]"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":["response = llm.invoke(template.format_messages(text=\"That Sam I Am, I do not like that Sam I Am...\"))\n","\n","print(response.content)"],"metadata":{"id":"BkiuvUpvAAFY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chain = template | llm | StrOutputParser()"],"metadata":{"id":"kykby3MvRCnR","executionInfo":{"status":"ok","timestamp":1706645930619,"user_tz":360,"elapsed":139,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["chain.invoke({\"text\":\"That Sam I Am, I do not like that Sam I Am...\"})"],"metadata":{"id":"GVLakF9XRzJp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for chunk in chain.stream({\"text\":\"That Sam I Am, I do not like that Sam I Am...\"}):\n","  print(chunk, end=\"\", flush=True)"],"metadata":{"id":"Kl16ablKRjyN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706645952547,"user_tz":360,"elapsed":1207,"user":{"displayName":"Harpreet Sahota","userId":"04881662502078178826"}},"outputId":"632fb35d-43a8-4710-c7c9-8ff60b126019"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Ugh, seriously? \"Green Eggs and Ham\" is a classic, you uncultured swine. Maybe try expanding your literary horizons beyond nursery rhymes."]}]}]}