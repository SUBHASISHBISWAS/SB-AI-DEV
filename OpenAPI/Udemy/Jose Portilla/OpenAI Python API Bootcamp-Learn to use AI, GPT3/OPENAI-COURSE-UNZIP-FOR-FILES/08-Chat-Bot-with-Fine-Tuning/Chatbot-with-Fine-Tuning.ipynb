{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f31f8d3d",
   "metadata": {},
   "source": [
    "<a href = \"https://www.pieriantraining.com\"><img src=\"../PT Centered Purple.png\"> </a>\n",
    "\n",
    "<em style=\"text-align:center\">Copyrighted by Pierian Training</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fca1ed1",
   "metadata": {},
   "source": [
    "# Fine-Tuning a Model - ChatBot Example\n",
    "\n",
    "In this project, we'll explore how to fine-tune a GPT model such as text-babbage model with our own data set. You should note, this may not be needed for more advanced text-davinci models or future GPT-4 models, but let's explore the process of creating our own custom fine-tuning data set, formatting it for OpenAI, and then training and calling our own custom model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c36ce4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55f3f840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import tiktoken \n",
    "import pandas as pd\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1899585",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We've gathered a data from Kaggle with a set of Questions and Answers from StackOverflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "557d4c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_df = pd.read_csv(\"python_qa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d4d4960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ClosedDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>ParentId</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11060</td>\n",
       "      <td>912.0</td>\n",
       "      <td>2008-08-14T13:59:21Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>How should I unit test a code-generator?</td>\n",
       "      <td>This is a difficult and open-ended question I ...</td>\n",
       "      <td>11060</td>\n",
       "      <td>I started writing up a summary of my experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17250</td>\n",
       "      <td>394.0</td>\n",
       "      <td>2008-08-20T00:16:40Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>Create an encrypted ZIP file in Python</td>\n",
       "      <td>I'm creating an ZIP file with ZipFile in Pytho...</td>\n",
       "      <td>17250</td>\n",
       "      <td>I created a simple library to create a passwor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31340</td>\n",
       "      <td>242853.0</td>\n",
       "      <td>2008-08-27T23:44:47Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71</td>\n",
       "      <td>How do threads work in Python, and what are co...</td>\n",
       "      <td>I've been trying to wrap my head around how th...</td>\n",
       "      <td>31340</td>\n",
       "      <td>Yes, because of the Global Interpreter Lock (G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34020</td>\n",
       "      <td>3561.0</td>\n",
       "      <td>2008-08-29T05:43:16Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>Are Python threads buggy?</td>\n",
       "      <td>A reliable coder friend told me that Python's ...</td>\n",
       "      <td>34020</td>\n",
       "      <td>Python threads are good for concurrent I/O pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34570</td>\n",
       "      <td>577.0</td>\n",
       "      <td>2008-08-29T16:10:41Z</td>\n",
       "      <td>2011-11-08T16:11:43Z</td>\n",
       "      <td>13</td>\n",
       "      <td>What is the best quick-read Python book out th...</td>\n",
       "      <td>I am taking a class that requires Python. We w...</td>\n",
       "      <td>34570</td>\n",
       "      <td>I loved Dive Into Python, especially if you're...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  OwnerUserId          CreationDate            ClosedDate  Score  \\\n",
       "0  11060        912.0  2008-08-14T13:59:21Z                   NaN     18   \n",
       "1  17250        394.0  2008-08-20T00:16:40Z                   NaN     24   \n",
       "2  31340     242853.0  2008-08-27T23:44:47Z                   NaN     71   \n",
       "3  34020       3561.0  2008-08-29T05:43:16Z                   NaN     17   \n",
       "4  34570        577.0  2008-08-29T16:10:41Z  2011-11-08T16:11:43Z     13   \n",
       "\n",
       "                                               Title  \\\n",
       "0           How should I unit test a code-generator?   \n",
       "1             Create an encrypted ZIP file in Python   \n",
       "2  How do threads work in Python, and what are co...   \n",
       "3                          Are Python threads buggy?   \n",
       "4  What is the best quick-read Python book out th...   \n",
       "\n",
       "                                                Body  ParentId  \\\n",
       "0  This is a difficult and open-ended question I ...     11060   \n",
       "1  I'm creating an ZIP file with ZipFile in Pytho...     17250   \n",
       "2  I've been trying to wrap my head around how th...     31340   \n",
       "3  A reliable coder friend told me that Python's ...     34020   \n",
       "4  I am taking a class that requires Python. We w...     34570   \n",
       "\n",
       "                                              Answer  \n",
       "0  I started writing up a summary of my experienc...  \n",
       "1  I created a simple library to create a passwor...  \n",
       "2  Yes, because of the Global Interpreter Lock (G...  \n",
       "3  Python threads are good for concurrent I/O pro...  \n",
       "4  I loved Dive Into Python, especially if you're...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ee1191",
   "metadata": {},
   "source": [
    "### Fine-Tuning Formatting\n",
    "\n",
    "The formatting for a fine-tuning data set involves a prompt and expected completion. This leads fine-tuning to be a great choice for dialogue instances, such as question and answer or customer support.\n",
    "\n",
    "The format should look like the following (a list of dictionaries):\n",
    "\n",
    "    [{\"prompt\": \"some prompt string\",\"completion\":\"the best completed text option given the prompt\"},]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8b5fb0",
   "metadata": {},
   "source": [
    "Convert the information from the CSV to fine tuning format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d94f0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = qa_df[\"Body\"], qa_df[\"Answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b937678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    This is a difficult and open-ended question I ...\n",
       "1    I'm creating an ZIP file with ZipFile in Pytho...\n",
       "2    I've been trying to wrap my head around how th...\n",
       "3    A reliable coder friend told me that Python's ...\n",
       "4    I am taking a class that requires Python. We w...\n",
       "Name: Body, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3514d6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I started writing up a summary of my experienc...\n",
       "1    I created a simple library to create a passwor...\n",
       "2    Yes, because of the Global Interpreter Lock (G...\n",
       "3    Python threads are good for concurrent I/O pro...\n",
       "4    I loved Dive Into Python, especially if you're...\n",
       "Name: Answer, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858210e7",
   "metadata": {},
   "source": [
    "Now we can create the list of dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cad2ae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_openai_format = [{\"prompt\" : q, \"completion\": a} for q, a in zip(questions, answers)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3707ed",
   "metadata": {},
   "source": [
    "Now let's explore a single prompt/completion combo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0f61961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'I am taking a class that requires Python. We will review the language in class next week, and I am a quick study on new languages, but I was wondering if there are any really great Python books I can grab while I am struggling through the basics of setting up my IDE, server environment and all those other \"gotchas\" that come with a new programming language. Suggestions?\\n',\n",
       " 'completion': \"I loved Dive Into Python, especially if you're a quick study.  The beginning basics are all covered (and may move slowly for you), but the latter few chapters are great learning tools.\\n\\nPlus, Pilgrim is a pretty good writer.\\n\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_openai_format[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71b25b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4429"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qa_openai_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe8859b",
   "metadata": {},
   "source": [
    "## Price Estimation\n",
    "\n",
    "In case you are ever worried about how many tokens your text actually has (to get an estimate of your costs) OpenAI has a library called \"tiktoken\", which allows you to estimate a cost based on token counts.\n",
    "\n",
    "Splitting text strings into tokens is useful because models like GPT-3 see text in the form of tokens. Knowing how many tokens are in a text string can tell you (a) whether the string is too long for a text model to process and (b) how much an OpenAI API call costs (as usage is priced by token). Different models use different encodings.\n",
    "\n",
    "**tiktoken** supports 3 different encodings for OpenAI models:\n",
    "\n",
    "* \"gpt2\" for most gpt-3 models\n",
    "* \"p50k_base\" for code models, and Davinci models, like \"text-davinci-003\"\n",
    "* \"cl100k_base\" for text-embedding-ada-002\n",
    "\n",
    "Make sure to view the pricing page on the OpenAI page for full information, for now, we'll cut down the data size so we don't spend too much money during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6474d321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string, encoding_name):\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fc44041",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f497600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_data.json\", \"w\") as f:\n",
    "    for entry in qa_openai_format[:dataset_size]:\n",
    "        f.write(json.dumps(entry))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44119cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counter = 0\n",
    "for element in qa_openai_format[:dataset_size]:\n",
    "    for key, value in element.items():\n",
    "        token_counter+=num_tokens_from_string(value,'p50k_base')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14c7e484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 184352 tokens\n",
      "Fine tuning using babbage costs $0.0006 per 1000 tokens\n",
      "Estimated price: $0.11061119999999999\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {token_counter} tokens\")\n",
    "print(f\"Fine tuning using babbage costs $0.0006 per 1000 tokens\")\n",
    "print(f\"Estimated price: ${(4*token_counter / 1000) * 0.0006}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819b7cf9",
   "metadata": {},
   "source": [
    "## Command Line for Fine-Tuning\n",
    "\n",
    "Note, you can find the full official guide here:\n",
    "\n",
    "https://platform.openai.com/docs/guides/fine-tuning\n",
    "\n",
    "OpenAI recommends using the terminal/command line via their OpenAI tool, which you have by simply running:\n",
    "\n",
    "    pip install --upgrade openai\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0167423d",
   "metadata": {},
   "source": [
    "Now you can head over to the terminal to fine tune the model using the following command:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf552a3",
   "metadata": {},
   "source": [
    "    openai api fine_tunes.create -t training_data.json -m babbage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3336801a",
   "metadata": {},
   "source": [
    "Alternatively we can also run this in notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4179287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!openai api fine_tunes.create -t training_data.json -m babbage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9441a45b",
   "metadata": {},
   "source": [
    "You can use:\n",
    "\n",
    "*openai api fine_tunes.list* to get a list of your fine tuning jobs, \n",
    "\n",
    "*openai api fine_tunes.get -i <YOUR_FINE_TUNE_JOB_ID>* to get the debug log of your fine tuning process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea97c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "!babbage:ft-personal-2023-02-09-13-52-20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b240d4",
   "metadata": {},
   "source": [
    "After training you can extract your fine tuned model using *openai api fine_tunes.list* and copy the fine_tuned_model entry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677cf744",
   "metadata": {},
   "source": [
    "## OpenAI API\n",
    "\n",
    "Remember to use the notebook as shown, you must set your OpenAI API Key as an environment variable. Obviously, there are many ways you could provide your API Key to the Python code, input() or even hard-coded, but those are typically not recommended for safety reasons. Having it as an environment variable let's the key live on the computer, but not actually be present in the code.\n",
    "\n",
    "### Set-up Open AI API Key\n",
    "\n",
    "We'll only need to do this once per computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e865f7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment below and swap in your key to place your environment key using Python\n",
    "# Then you can delete the key string and the code cell below will still work!\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"Your key goes here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "36b9fcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5a420168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "response = openai.Completion.create(\n",
    "    model=\"babbage:ft-personal-2023-02-09-13-52-20\",\n",
    "    prompt=\"What are good python books?\",\n",
    "    max_tokens=128,\n",
    "    temperature=0.7,\n",
    "    top_p=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "34ea8c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "If you're programming in python, a good introductory book is \"Programming Python\". It covers most of the basics and has a good section on libraries.\n",
      "I'd recommend this book if you're new to python, or if you're already experienced. I'd also recommend \"Learn Python The Hard Way\" .\n",
      "\n",
      "For a more advanced book, \"Mastering Python\" is a good starting point.\n",
      "\n",
      "\"The Python Bible\" is a good reference too.\n",
      "\n",
      "Pythonista - an excellent book by Michael J. pearlman.\n",
      "\n",
      "Books also available in PDF form:\n",
      "\n",
      "\"Mastering Python\".\n"
     ]
    }
   ],
   "source": [
    "print(response[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8144d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5455cba45dca8dec86c35d949ecf676492206ef67d9fdf2560e140a882ab099f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
